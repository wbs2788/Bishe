\chapter{基于思维链增强的视频生成前置安全检测方法}
\section{引言}
\subsection{视频生成面临的输入端安全威胁}
\subsection{现有检测方法的局限性}
\subsection{本章研究内容}

\section{轻量化大语言模型检测架构}
作为文生视频全流程防御体系的第一道防线，输入端检测模块的设计面临着严苛的“不可能三角”约束：
既要具备理解隐晦语义与多步推理的高准确性，又要满足视频生成服务对低延迟的实时性要求，同时还需控制显存占用以适应消费级的部署环境。
传统的基于 BERT 或 RoBERTa 的判别式小模型虽然速度极快，但缺乏逻辑推理能力，难以应对复杂的“越狱”攻击；
而 GPT-4 或 Llama-3.1-70B 等超大模型虽然理解力强，但其推理成本与延迟对于前置检测任务而言过于昂贵。

鉴于此，本章提出了一种基于 Llama-3.1-8B 的轻量化检测架构。
该架构摒弃了“超大模型暴力求解”的路径，转而通过参数高效微调（LoRA）与思维链（CoT）技术的结合，在百亿级参数规模下激发模型的安全推理能力，实现了检测精度与推理效率的最佳平衡。

\subsection{基座模型选型}

在基座模型的选型上，本研究最终锁定了 Llama-3.1-8B（此处指 Llama-3.1 系列中的 8B 参数量级指令微调版本）。
这一选择是基于对当前开源大模型在安全检测任务中性能边界的深度量化分析，代表了当前端侧与边缘侧模型的最新技术水位。

\subsubsection{检测精度与推理延迟的帕累托最优}

作为视频生成的“前置预检模块”（Pre-check Module），检测器的响应速度直接决定了用户体验的流畅度。
Llama-3.1-8B 在计算复杂度与推理能力之间找到了一个理想的甜点区：
\begin{itemize}
    \item 推理能力的质变：与早期的 7B 模型相比，Llama-3.1-8B 通过在 15T Token 上的过度训练（Over-training），展现出了媲美以往 30B+ 模型的逻辑推理能力。它具备了处理复杂隐喻和长尾安全知识的“涌现”特性，能够有效执行思维链（CoT）推理。
    \item 部署效率的优势：相比于 70B 或 405B 版本，8B 模型的参数量仅为其 1/10 甚至 1/50。在半精度（BF16）或 8-bit 量化下，其显存占用可控制在 10GB-16GB 之间，能够轻松部署在单张消费级显卡（如 RTX 3090/4090）上，并实现毫秒级的 Token 生成速度，满足高并发工业场景的需求。
    \item 核心架构特性：分组查询注意力 (GQA)Llama-3.1-8B 采用了分组查询注意力（Grouped Query Attention, GQA）机制，这是其实现高吞吐量的关键技术。
    在标准的多头注意力（Multi-head Attention, MHA）中，Query、Key、Value 的头数相同，导致推理时的 KV Cache 显存占用巨大。而 GQA 将 Query 头分组，每组共享一对 Key 和 Value 头。
    在本模型中，Query 头数为 32，而 KV 头数仅为 8（即 4:1 的分组比例）。
    这不仅显著降低了推理过程中的显存占用，更大幅减少了显存带宽需求，使得模型在处理长 Context（如包含长篇剧情描述的 Prompt）时依然保持极高的吞吐效率。
\end{itemize}

\subsubsection{核心架构特性：分组查询注意力}
模型参数规格详解Llama-3.1-8B 的具体网络拓扑结构与参数配置如表 3-1 所示。
该模型采用了标准的 Transformer Decoder-only 架构，配合 128k 的超长上下文窗口，使其能够精准理解和分析长篇幅的视频脚本指令。
\begin{table}[!t]
    \centering
    \bicaption{Llama-3.1-8B 模型参数维度规格表}{Hyperparameter Specifications of Llama-3.1-8B Base Model}
    \label{tab:model_hyperparameters}
    \setlength{\tabcolsep}{8pt} % 优化列间距
    \renewcommand{\arraystretch}{1.2} % 略微增加行高，提升可读性
    \begin{tabularx}{\textwidth}{l l X}
        \toprule
        \textbf{参数维度 (Hyperparameter)} & \textbf{数值 (Value)} & \textbf{技术说明 (Description)} \\
        \midrule
        参数总量 (Total Parameters) & 8.03 B & 平衡了推理能力与显存占用，适合单卡部署。 \\
        词表大小 (Vocab Size) & 128,256 & 增强了对多语言及长尾词汇的编码效率。 \\
        隐藏层维度 (Hidden Size) & 4,096 & 模型的特征宽度，保证了足够的语义表征容量。 \\
        网络层数 (Layers) & 32 & 标准深度，足以捕捉复杂的逻辑依赖关系。 \\
        注意力头数 (Attention Heads) & 32 & Query 头的数量。 \\
        KV 头数 (KV Heads) & 8 & 采用 GQA 机制，大幅压缩 KV Cache。 \\
        上下文窗口 (Context Window) & 128k & 支持超长文本输入，适应剧本级视频生成指令。 \\
        位置编码 (Positional Embed) & RoPE & 旋转位置编码，提升长序列外推能力。 \\
        激活函数 (Activation) & SwiGLU & 相比 ReLU 具有更好的收敛性和性能。 \\
        \bottomrule
    \end{tabularx}
\end{table}

通过选用 Llama-3.1-8B，我们确保了检测架构在底层算力层面具备了高效运行的物理基础，为后续引入 LoRA 微调与 CoT 推理提供了强大的语义理解底座。

\subsection{基于低秩自适应的参数高效微调}

\subsection{基于低秩自适应的微调机制}

对于十亿级参数量的 Llama-3.1，全参数微调（Full Fine-tuning）不仅对显存资源要求极高，且容易导致模型在小规模偏好数据集上发生灾难性遗忘（Catastrophic Forgetting）。
因此，本文采用低秩自适应（Low-Rank Adaptation, LoRA）技术进行参数高效微调。

\textbf{（1）低秩矩阵注入形式LoRA。} 假设模型在特定任务上的权重更新矩阵具有极低的本征秩（Intrinsic Rank）。
对于预训练的权重矩阵 $W_0 \in \mathbb{R}^{d \times k}$，我们将参数更新量 $\Delta W$ 分解为两个低秩矩阵 $B \in \mathbb{R}^{d \times r}$ 和 $A \in \mathbb{R}^{r \times k}$ 的乘积，即：
\begin{equation}
W' = W_0 + \Delta W = W_0 + \frac{\alpha}{r} B A.
\end{equation}
其中，$r \ll \min(d, k)$ 为秩的大小，$\alpha$ 为缩放系数。在训练过程中，$W_0$ 保持冻结，仅优化 $A$ 和 $B$。
初始化阶段，矩阵 $A$采用高斯分布初始化，这为模型提供了随机的梯度起点，使其能够探索参数空间；
矩阵 $B$ 初始化为全零矩阵，这样可以确保在训练的第一步，$BA = 0$，从而使得 $W' = W_0$。这种“零残差”的起点能有效防止初始阶段的随机噪声破坏预训练模型已学习到的特征表达。

\textbf{（2）针对安全推理的微调策略。} 在前置检测任务中，模型需要学习特定的安全分类体系与思维链推理模式。根据 LLM 微调的经验法则，自注意力模块中的**查询（Query, $W_q$）与值（Value, $W_v$）**投影层对语义理解与文本生成的贡献最大。因此，我们仅对这两层应用 LoRA 更新。
考虑到安全检测属于判别式任务，其任务边界相对清晰，不需要过大的容量。我们将秩设置为 $r=16$。

\textbf{（3）参数量效率分析.} 基于上述配置，Llama-3.1-8B 模型的可训练参数量仅为 12.8M，占总参数量（8.03B）的比例约为 0.16\%。
这种极低参数量的特性不仅显著降低了训练显存需求，还允许我们在部署时通过动态加载不同的权重来切换不同的安全策略，而无需重新加载整个基座模型。

\section{基于思维链增强的检测方法}

虽然 Llama-3.1-8B + LoRA 提供了强大的底层语义理解能力，但若缺乏明确的指令引导，模型仍难以在复杂的语境下做出符合人类价值观的判断。
为此，本节提出了“策略即提示（Policy-as-Prompt）”与“思维链（Chain-of-Thought）”两大核心机制，前者负责将抽象的安全规范转化为模型可执行的自然语言指令，后者负责引导模型将单步判别任务分解为多步逻辑推理过程。

\subsection{策略即提示机制}

在传统的审核系统中，安全规则通常以代码逻辑或硬编码的关键词列表形式存在，这种“显式规则”难以覆盖千变万化的语言表达。
本研究提出的 Policy-as-Prompt 机制，旨在将复杂的安全审核标准转化为结构化的系统提示词，直接注入模型的上下文窗口中。
这种方法利用大语言模型的指令遵循能力，实现了从“规则匹配”到“规则理解”的范式转变。

\subsubsection{风险分类体系}

为了建立清晰的审核边界，本研究结合工业界主流规范（如 MLCommons），定义了一套包含四个核心维度的风险分类体系。
该体系不仅涵盖了显式的违规内容，还特别针对视频生成的特性，增加了对动态行为和隐喻描述的定义。

\textbf{（1）暴力与血腥}：涉及对生物体造成物理伤害、残害或杀戮的逼真描述；以及对战争、酷刑、大规模伤亡事件的视觉化重现。例如连贯的攻击动作序列（如刺杀过程演示）、制造武器的详细步骤教程等。

\textbf{（2）色情与淫秽}：涉及性行为、生殖器官的露骨描写；以及具有性暗示的姿势、恋童癖内容（CSAM）或非自愿的性内容（NCII）。需要拦截使用隐晦俚语的生成请求。

\textbf{（3）偏见与歧视}：针对受保护群体（种族、性别、宗教、残疾等）的仇恨言论、刻板印象强化或非人化描述。例如生成“特定种族人群正在实施犯罪”的偏见性画面。

\textbf{（4）非法行为}：宣扬、指导或演示违反法律的活动。例如毒品制造与交易、网络攻击演示、洗钱教程、恐怖主义宣传等。

\subsection{系统提示词模板设计}

基于上述分类体系，我们设计了结构化的 System Prompt。该 Prompt 采用了“角色扮演 + 规则注入 + 输出约束”的三段式结构，强制模型在推理前加载完整的安全知识库。
% TODO: fig

\subsection{思维链推理范式}

\section{实验结果与分析}
\subsection{实验设置}
\subsection{主实验结果}
\subsection{消融实验}
\subsection{定性试验分析}

\section{本章小结}